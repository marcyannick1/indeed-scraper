# Projet de Scraping - France Travail

Scrapeur d'offres d'emploi sur candidat.francetravail.fr, avec API FastAPI et stockage MongoDB.
Permet de rechercher des offres selon un mot-clÃ© et une localisation (dÃ©partement ou commune), puis de les afficher via
une API REST.

## ğŸ‘¥ Membres du Groupe

- **Yannick COULIBALY**
- **Rufus Hilaire MOUAKASSA**
- **Abondance KAZADI**

## ğŸ“ FonctionnalitÃ©s

- âœ… Scraping automatisÃ© d'offres d'emploi via Scrapy
- âœ… Extraction des dÃ©tails d'annonce (titre, entreprise, lieu, salaire, type de contratâ€¦)
- âœ… Nettoyage des donnÃ©es via pipelines (dates, sauts de lignes, espacesâ€¦)
- âœ… API REST FastAPI pour exposer les donnÃ©es
- âœ… Stockage dans MongoDB (local ou cloud)
- âœ… Interface frontend React/Vue.js pour visualiser les offres
- âœ… Script interactif pour lancer le scraping facilement

## ğŸ“‚ Structure du Projet

```
jobs_scraper/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ database.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ JobItem.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ jobs.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”œâ”€â”€ scraper/                    # Scrapy spider
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â””â”€â”€ jobs_spider.py
â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”œâ”€â”€ items.py
â”‚   â”œâ”€â”€ middlewares.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ run_spider.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”œâ”€â”€ frontend/                   # Frontend React
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ App.js
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â””â”€â”€ vite.config.js
â””â”€â”€ README.md
```

## ğŸš€ Installation

### 1. Cloner le projet

```bash
git clone https://github.com/marcyannick1/jobs-scraper.git
cd jobs-scraper
```

### 2. CrÃ©er un environnement virtuel

```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

### 3. Installer les dÃ©pendances backend

```bash
pip install -r backend/requirements.txt
pip install -r scraper/requirements.txt
```

### 4. Installer les dÃ©pendances frontend

```bash
cd frontend
npm install
cd ..
```

### 5. Configuration des variables d'environnement

CrÃ©er un fichier `.env` dans les dossiers `backend/` et `scraper/` :

**backend/.env**

```env
MONGO_URI=mongodb://localhost:27017/
MONGO_DATABASE=jobs_db
```

**scraper/.env**

```env
MONGO_URI=mongodb://localhost:27017/
MONGO_DATABASE=jobs_db
```

## ğŸ•·ï¸ Lancer le scraping

### MÃ©thode interactive

Lance le script interactif depuis le dossier `scraper/` :

```bash
cd scraper
python run_spider.py
```

Puis saisir :

- **Mot-clÃ©** (ex: `python`, `dÃ©veloppeur`, `data`)
- **Code INSEE** du dÃ©partement ou de la commune (ex: `75D` pour Paris, `92050` pour Nanterre)

### MÃ©thode en ligne de commande

```bash
cd scraper
scrapy crawl jobs_spider -a keyword="python" -a location="75D"
```

## ğŸ–¥ï¸ Lancer l'API Backend

Depuis le dossier `backend/` :

```bash
cd backend
uvicorn main:app --reload
```

## ğŸŒ Lancer le Frontend

Depuis le dossier `frontend/` :

```bash
cd frontend
npm run dev
```

**AccÃ¨s Ã  l'interface :**

- ğŸ“ [http://localhost:3000](http://localhost:3000) ou [http://localhost:5173](http://localhost:5173)

## ğŸ“¦ Endpoints API

### **GET** `/jobs`

RÃ©cupÃ¨re toutes les offres d'emploi

**Exemple de rÃ©ponse :**

```json
[
  {
    "_id": "66bfcf4e5a3f4a6e9f1dca88",
    "title": "DÃ©veloppeur Python Back-End",
    "company": "LBESOFT",
    "location": {
      "postalCode": "75009",
      "city": "Paris",
      "region": "Ãle-de-France",
      "country": "FRANCE"
    },
    "contractType": "CDI",
    "salary": {
      "min": 38000.0,
      "max": 45000.0,
      "unit": "YEAR"
    },
    "description": "Nous recherchons un dÃ©veloppeur Python expÃ©rimentÃ© pour renforcer notre Ã©quipe backend...",
    "skills": [
      "Python",
      "Django",
      "REST API",
      "Git",
      "MongoDB"
    ],
    "experience": "3 ans",
    "publishDate": "2025-07-22T00:00:00",
    "url": "https://candidat.francetravail.fr/offres/recherche/detail/195MWHD",
    "companyInfo": {
      "size": "50 Ã  99 salariÃ©s",
      "description": "LBESOFT est une sociÃ©tÃ© spÃ©cialisÃ©e dans les solutions logicielles sur mesure.",
      "url": "https://www.lbesoft.fr"
    }
  }
]
```

### **GET** `/jobs/{job_id}`

RÃ©cupÃ¨re une offre spÃ©cifique par son ID

## ğŸ—ƒï¸ Structure des DonnÃ©es

Chaque offre d'emploi contient les champs suivants :

| Champ         | Type     | Description                      |
|---------------|----------|----------------------------------|
| `_id`         | String   | Identifiant unique MongoDB       |
| `title`       | String   | Titre du poste                   |
| `company`     | String   | Nom de l'entreprise              |
| `location`    | Object   | Informations de localisation     |
| `contractType` | String   | Type de contrat (CDI, CDD, etc.) |
| `salary`      | Object   | Fourchette de salaire            |
| `description` | String   | Description complÃ¨te du poste    |
| `skills`      | Array    | CompÃ©tences requises             |
| `experience`  | String   | ExpÃ©rience requises              |
| `publishDate` | DateTime | Date de publication              |
| `url`         | String   | URL de l'offre originale         |
| `companyInfo` | Object   | Informations sur l'entreprise    |

## ğŸ› ï¸ Technologies UtilisÃ©es

### Backend

- **FastAPI** - Framework web moderne et rapide
- **MongoDB** - Base de donnÃ©es NoSQL
- **PyMongo** - Driver MongoDB pour Python

### Scraper

- **Scrapy** - Framework de scraping web
- **PyMongo** - Driver MongoDB pour Python

### Frontend

- **React/Vue.js** - Framework JavaScript
- **Axios** - Client HTTP
- **Tailwind** - Framework CSS

## ğŸ“‹ TODO / AmÃ©liorations

- [ ] Ajout de filtres avancÃ©s (salaire, type de contrat)
- [ ] SystÃ¨me de notifications pour nouvelles offres
- [ ] Export des donnÃ©es (CSV, Excel)
- [ ] Interface d'administration
- [ ] Cache Redis pour amÃ©liorer les performances
- [ ] Dockerisation complÃ¨te du projet
- [ ] CI/CD avec GitHub Actions
- [ ] Tests d'intÃ©gration
- [ ] Monitoring et logs

## ğŸ› RÃ©solution de ProblÃ¨mes

### Erreur de connexion MongoDB

```bash
# VÃ©rifier que MongoDB est lancÃ©
sudo systemctl status mongod

# Ou avec Docker
docker run -d -p 27017:27017 mongo:latest
```

### Erreur de dÃ©pendances

```bash
# Mettre Ã  jour pip
pip install --upgrade pip

# RÃ©installer les dÃ©pendances
pip install -r requirements.txt --force-reinstall
```

### ProblÃ¨me de scraping (anti-bot)

- Ajuster les dÃ©lais dans `settings.py`
- Utiliser des proxies rotatifs
- Modifier les User-Agents